"""
ResponseDrafter Agent
ì´ë©”ì¼ ë‹µë³€ ì´ˆì•ˆ ìƒì„±
"""
from typing import Dict, List, Optional
from utils.llm_handler import LLMHandler


class ResponseDrafter:
    """ë‹µë³€ ì´ˆì•ˆ ìƒì„± Agent"""
    
    def __init__(self, llm_handler: LLMHandler):
        """
        ResponseDrafter ì´ˆê¸°í™”
        
        Args:
            llm_handler: LLM í•¸ë“¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
        """
        self.llm = llm_handler
    
    def draft_response(
        self,
        email: Dict,
        classification: Dict,
        priority_analysis: Dict
    ) -> Dict:
        """
        ì´ë©”ì¼ ë‹µë³€ ì´ˆì•ˆ ìƒì„±
        
        Args:
            email: ì´ë©”ì¼ ì •ë³´
            classification: ë¶„ë¥˜ ê²°ê³¼
            priority_analysis: ìš°ì„ ìˆœìœ„ ë¶„ì„ ê²°ê³¼
                
        Returns:
            ë‹µë³€ ì´ˆì•ˆ ê²°ê³¼
                - draft: ë‹µë³€ ì´ˆì•ˆ í…ìŠ¤íŠ¸
                - tone: ì‚¬ìš©í•œ í†¤ (formal/friendly)
                - suggested_subject: ì œì•ˆ ì œëª©
                - should_respond: ë‹µë³€ í•„ìš” ì—¬ë¶€
        """
        print(f"  ğŸ¤– ResponseDrafter: {email['subject'][:50]}...")
        
        category = classification.get('category', 'work')
        priority = priority_analysis.get('priority', 'medium')
        
        # ìŠ¤íŒ¸/ë§ˆì¼€íŒ…ì€ ë‹µë³€ ë¶ˆí•„ìš”
        if category in ['spam', 'marketing']:
            return {
                'draft': None,
                'tone': None,
                'suggested_subject': None,
                'should_respond': False,
                'reason': 'ë‹µë³€ì´ í•„ìš”í•˜ì§€ ì•Šì€ ì´ë©”ì¼ì…ë‹ˆë‹¤.'
            }
        
        # ì ì ˆí•œ í†¤ ì„ íƒ
        tone = self._select_tone(category, priority)
        
        # LLMìœ¼ë¡œ ë‹µë³€ ì´ˆì•ˆ ìƒì„± (í•„ìˆ˜)
        draft = self._generate_draft_with_llm(email, classification, priority_analysis, tone)
        
        # LLM ì‹¤íŒ¨ ì‹œ ì´ë¯¸ ì—ëŸ¬ê°€ ë°œìƒí–ˆì„ ê²ƒì„
        if not draft:
            raise ValueError(
                "LLM ë‹µë³€ ìƒì„± ì‹¤íŒ¨. OpenAI API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
            )
        
        # ì œëª© ìƒì„±
        suggested_subject = f"Re: {email['subject']}"
        
        return {
            'draft': draft,
            'tone': tone,
            'suggested_subject': suggested_subject,
            'should_respond': True,
            'reason': 'ë‹µë³€ ì´ˆì•ˆì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.'
        }
    
    def _select_tone(self, category: str, priority: str) -> str:
        """
        ì ì ˆí•œ ë‹µë³€ í†¤ ì„ íƒ
        
        Args:
            category: ì´ë©”ì¼ ì¹´í…Œê³ ë¦¬
            priority: ìš°ì„ ìˆœìœ„
            
        Returns:
            í†¤ (formal/friendly)
        """
        # ê¸´ê¸‰í•˜ê±°ë‚˜ ì—…ë¬´ ê´€ë ¨ì€ ê³µì‹ì ìœ¼ë¡œ
        if category == 'urgent' or priority == 'high':
            return 'formal'
        
        # ë‚´ë¶€ ì—…ë¬´ëŠ” ì¹œê·¼í•˜ê²Œ
        if category == 'internal':
            return 'friendly'
        
        # ê¸°ë³¸ê°’: ê³µì‹ì 
        return 'formal'
    
    def _generate_draft_with_llm(
        self,
        email: Dict,
        classification: Dict,
        priority_analysis: Dict,
        tone: str
    ) -> str:
        """
        LLMì„ ì‚¬ìš©í•œ ë‹µë³€ ì´ˆì•ˆ ìƒì„±
        
        Args:
            email: ì´ë©”ì¼ ì •ë³´
            classification: ë¶„ë¥˜ ê²°ê³¼
            priority_analysis: ìš°ì„ ìˆœìœ„ ë¶„ì„
            tone: í†¤
            
        Returns:
            ë‹µë³€ ì´ˆì•ˆ í…ìŠ¤íŠ¸
        """
        body_preview = email['body'][:600] if len(email['body']) > 600 else email['body']
        category = classification.get('category', 'work')
        priority = priority_analysis.get('priority', 'medium')
        
        # í†¤ì— ë”°ë¥¸ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ
        tone_guide = {
            'formal': "ê³µì‹ì ì´ê³  ì •ì¤‘í•œ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. 'ì•ˆë…•í•˜ì„¸ìš”', 'ê°ì‚¬í•©ë‹ˆë‹¤' ë“± ê²©ì‹ ìˆëŠ” í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.",
            'friendly': "ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. í•˜ì§€ë§Œ ì—¬ì „íˆ ì „ë¬¸ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
        }
        
        prompt = f"""ë‹¤ìŒ ì´ë©”ì¼ì— ëŒ€í•œ ë‹µë³€ ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.

ë°›ì€ ì´ë©”ì¼:
ë°œì‹ ì: {email['from']}
ì œëª©: {email['subject']}
ë³¸ë¬¸:
{body_preview}

ì´ë©”ì¼ ì •ë³´:
- ì¹´í…Œê³ ë¦¬: {category}
- ìš°ì„ ìˆœìœ„: {priority}
- í†¤: {tone_guide.get(tone, tone_guide['formal'])}

ë‹µë³€ ì‘ì„± ê°€ì´ë“œ:
1. ì¸ì‚¬ë§ë¡œ ì‹œì‘
2. ì´ë©”ì¼ ë‚´ìš©ì„ ì´í•´í–ˆìŒì„ í‘œí˜„
3. í•µì‹¬ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì— ë‹µë³€
4. ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ë©´ ìš”ì²­
5. ì •ì¤‘í•œ ë§ˆë¬´ë¦¬

í•œêµ­ì–´ë¡œ 3-5ë¬¸ë‹¨ ì •ë„ë¡œ ì‘ì„±í•˜ì„¸ìš”.
ì„œëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

ë‹µë³€ ì´ˆì•ˆ:"""

        try:
            draft = self.llm.generate(
                prompt,
                max_tokens=500,
                temperature=0.7,
                system_prompt="ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì´ë©”ì¼ ì‘ì„± ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ìì—°ìŠ¤ëŸ½ê³  ì ì ˆí•œ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”."
            )
            
            return draft.strip()
            
        except Exception as e:
            error_msg = f"LLM ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}"
            print(f"  âš ï¸ {error_msg}")
            raise ValueError(error_msg) from e
    
    def batch_draft(self, analyzed_emails: List[Dict]) -> List[Dict]:
        """
        ì—¬ëŸ¬ ì´ë©”ì¼ì˜ ë‹µë³€ ì´ˆì•ˆì„ í•œ ë²ˆì— ìƒì„±
        
        Args:
            analyzed_emails: ìš°ì„ ìˆœìœ„ ë¶„ì„ëœ ì´ë©”ì¼ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ë‹µë³€ ì´ˆì•ˆ í¬í•¨ ì´ë©”ì¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for email in analyzed_emails:
            classification = email.get('classification', {})
            priority_analysis = email.get('priority_analysis', {})
            
            response_draft = self.draft_response(email, classification, priority_analysis)
            
            results.append({
                **email,
                'response_draft': response_draft
            })
        
        return results
    
    def get_response_stats(self, drafted_emails: List[Dict]) -> Dict:
        """
        ë‹µë³€ í•„ìš” ì—¬ë¶€ í†µê³„
        
        Args:
            drafted_emails: ë‹µë³€ ì´ˆì•ˆ ìƒì„±ëœ ì´ë©”ì¼ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í†µê³„ ì •ë³´
        """
        total = len(drafted_emails)
        need_response = sum(
            1 for email in drafted_emails
            if email.get('response_draft', {}).get('should_respond', False)
        )
        no_response = total - need_response
        
        return {
            'total': total,
            'need_response': need_response,
            'no_response': no_response,
            'response_rate': round(need_response / total * 100, 1) if total > 0 else 0
        }
    
    def refine_draft(
        self,
        original_draft: str,
        user_feedback: str
    ) -> str:
        """
        ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ë‹µë³€ ì´ˆì•ˆ ê°œì„ 
        
        Args:
            original_draft: ì›ë³¸ ë‹µë³€ ì´ˆì•ˆ
            user_feedback: ì‚¬ìš©ì í”¼ë“œë°±
            
        Returns:
            ê°œì„ ëœ ë‹µë³€ ì´ˆì•ˆ
        """
        prompt = f"""ë‹¤ìŒ ë‹µë³€ ì´ˆì•ˆì„ ì‚¬ìš©ì í”¼ë“œë°±ì— ë”°ë¼ ê°œì„ í•˜ì„¸ìš”.

ì›ë³¸ ë‹µë³€:
{original_draft}

ì‚¬ìš©ì í”¼ë“œë°±:
{user_feedback}

ê°œì„ ëœ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”:"""

        try:
            refined = self.llm.generate(
                prompt,
                max_tokens=500,
                temperature=0.7
            )
            
            return refined.strip()
            
        except Exception as e:
            print(f"  âš ï¸ ë‹µë³€ ê°œì„  ì˜¤ë¥˜: {str(e)}")
            return original_draft

